{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GWAS Locus Browser Generate Phenotype Variant File\n",
    "- **Author** - Frank Grenn\n",
    "- **Date Started** - April 2020\n",
    "- **Quick Description:** code to generate list of phenotype variants from other gwases. relies on files made in the coding variants scripts\n",
    "- **Data:** [GWAS Catalog](https://www.ebi.ac.uk/gwas/docs/file-download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/path/to/AppDataProcessing'\n",
    "WRKDIR = f\"{DATADIR}/phenovars\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get the Variants with Associated Disease\n",
    "get this from the file made in the coding variants scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(f\"{DATADIR}/codingvars/annotated_R05_tags_all_gwas.txt\",sep='\\t')\n",
    "tags.columns = ['GWAS', 'ID', 'Chr', 'Start', 'End', 'locnum', 'Ref', 'Alt',\n",
    "       'DISEASE', 'Func.refGene', 'Gene.refGene', 'GeneDetail.refGene',\n",
    "       'ExonicFunc.refGene', 'AAChange.refGene']\n",
    "print(tags.shape)\n",
    "print(tags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter for Variants with Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_tags = tags[tags.DISEASE.notnull()]\n",
    "disease_tags = disease_tags.drop_duplicates()\n",
    "disease_tags['Chr'] = disease_tags['Chr'].astype(np.int64)\n",
    "disease_tags['Start'] = disease_tags['Start'].astype(np.int64)\n",
    "disease_tags['End'] = disease_tags['End'].astype(np.int64)\n",
    "print(disease_tags.shape)\n",
    "print(disease_tags.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_tags.to_csv(f\"{WRKDIR}/PhenoVariant.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WRKDIR}/get_frequencies_annovar.sh\",\"w\") as bash_file:\n",
    "    bash_file.write(f'''#!/bin/bash\\n\\\n",
    "module load annovar\\n\\\n",
    "awk -F',' '{{print $3,$4,$5,$7,$8}}' '{WRKDIR}/PhenoVariant.csv' > phenovars.avinput\\n\\\n",
    "annotate_variation.pl --filter --build hg19 --dbtype gnomad211_genome --buildver hg19 --otherinfo {WRKDIR}/phenovars.avinput $ANNOVAR_DATA/hg19''')\n",
    "bash_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sbatch {WRKDIR}/get_frequencies_annovar.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Get LD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv(f\"{DATADIR}/gwas_risk_variants.csv\")\n",
    "print(variants.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenovars = disease_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make a ranges file to speed up plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = variants[['CHR','BP','BP']]\n",
    "ranges['ID']=\"r\"+ranges.index.astype(str)\n",
    "ranges.columns = ['CHR','Start','End','ID']\n",
    "ranges['Start'] = ranges['Start'].apply(lambda x: max(0,x - 1000000))\n",
    "ranges['End'] = ranges['End'] + 1000000\n",
    "print(ranges.shape)\n",
    "print(ranges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges.to_csv(f\"{WRKDIR}/LD/ranges.txt\",sep='\\t',index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run LD Commands\n",
    "probably better way to do this but works for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!mkdir {WRKDIR}/LD/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WRKDIR}/LD/calculateLD.swarm\", 'w') as outfile:\n",
    "    for i in range(len(variants.index)):\n",
    "        locus = variants.iloc[i]['Locus Number']\n",
    "        #print(locus)\n",
    "    \n",
    "        locus_phenovars = phenovars.loc[phenovars['locnum'] == locus]\n",
    "    \n",
    "        snp1 = str(variants.iloc[i]['CHR']) + \":\" + str(variants.iloc[i]['BP'])\n",
    "\n",
    "        if(len(locus_phenovars.index)!=0):\n",
    "            for i in range(len(locus_phenovars.index)):\n",
    "\n",
    "                snp2 = str(locus_phenovars.iloc[i]['Chr']) + \":\" + str(locus_phenovars.iloc[i]['Start'])\n",
    "\n",
    "\n",
    "                outfile.write(f\"plink --bfile /path/to/PD_FINAL_PLINK_2018/HARDCALLS_PD_september_2018_no_cousins --ld {snp1} {snp2} --extract range {WRKDIR}/LD/ranges.txt --out {snp1}_{snp2}\\n\")    \n",
    "outfile.close()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the swarm file\n",
    "print(f\"cd {WRKDIR}/LD/out\")\n",
    "print(f\"swarm -f {WRKDIR}/LD/calculateLD.swarm --partition quick --module plink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read stuff\n",
    "df = pd.DataFrame(columns=['rsid1','snp1','rsid2','snp2','r2','dprime'])\n",
    "for i in range(len(variants.index)):\n",
    "    locus = variants.iloc[i]['Locus Number']\n",
    "    #print(locus)\n",
    "    \n",
    "    locus_phenovars = phenovars.loc[phenovars['locnum'] == locus]\n",
    "    #print(locus_phenovars)\n",
    "    \n",
    "    snp1 = str(variants.iloc[i]['CHR']) + \":\" + str(variants.iloc[i]['BP'])\n",
    "    rsid1 = variants.iloc[i]['RSID']\n",
    "    if(len(locus_phenovars.index)!=0):\n",
    "        for i in range(len(locus_phenovars.index)):\n",
    "            #reset the read string to null\n",
    "            dataline='null'\n",
    "            snp2 = str(locus_phenovars.iloc[i]['Chr']) + \":\" + str(locus_phenovars.iloc[i]['Start'])\n",
    "            rsid2 = locus_phenovars.iloc[i]['ID']\n",
    "            #print(\"{} {}\".format(snp1, snp2))\n",
    "\n",
    "\n",
    "            \n",
    "            file = open(f\"{WRKDIR}/LD/out/\"+str(snp1)+\"_\"+str(snp2)+\".log\",\"r\")\n",
    "            \n",
    "            for line in file:\n",
    "                if re.search(\"R-sq\", line):\n",
    "                    dataline = line\n",
    "                    break\n",
    "            \n",
    "            #only add new data if 'R-sq' was found (meaning there was data in the log file and the 'null' value assigned earlier was overwritten)\n",
    "            if(dataline!='null'):\n",
    "                #mess with the strings\n",
    "                dataline = dataline.strip('R-sq = ')\n",
    "                dataline = dataline.strip(' ')\n",
    "                splitdata = dataline.split(\"D' =\")\n",
    "                Rsq = splitdata[0]\n",
    "                dprime = splitdata[1]\n",
    "            \n",
    "                df = df.append({'rsid1': rsid1,'snp1': snp1,'rsid2':rsid2, 'snp2': snp2, 'r2':Rsq.strip(' '), 'dprime':dprime.strip('\\n')}, ignore_index = True)\n",
    "        \n",
    "print(len(df.index))\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{DATADIR}/results/PhenotypeVariantLD.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Combine Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some formatting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePMIDLink(link):\n",
    "\tid = re.split(\"/\", link)[2]\n",
    "\treturn (\"<a href='https://\"+link+\"' target='_blank'>\"+id+\"</a>\")\n",
    "\t\n",
    "def formatCHRBPREFALT(chr,bp,ref,alt):\n",
    "\treturn str(chr)+\":\"+str(bp)+\":\"+str(ref)+\":\"+str(alt)\n",
    "\t\n",
    "def getNFE(frequencies):\n",
    "\tfreq = re.split(\",\", frequencies)[9]\n",
    "\treturn freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge with gwas catalog to get pmids and p values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(f\"{WRKDIR}/GWAS_catalogv1.0.2-associations.txt\", sep=\"\\t\",encoding='latin1')\n",
    "print(catalog.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(phenovars, catalog, how='left', left_on='ID',right_on='SNPS')\n",
    "\n",
    "print(merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge[['LINK','PUBMEDID']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge['PMID']=merge.apply(lambda x: generatePMIDLink(x.LINK),axis=1)\n",
    "merge['CHRBP_REFALT']=merge.apply(lambda x: formatCHRBPREFALT(x.Chr, x.Start, x.Ref, x.Alt), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the frequency data from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array for frequency df column names since annovar doesn't generate column names\n",
    "names = [\"db\", \"freq\", \"chr\", \"start\", \"end\", \"ref\", \"alt\"]\n",
    "frequencies = pd.read_csv(f\"{WRKDIR}/phenovars.avinput.hg19_gnomad211_genome_dropped\", sep=\"\\s\", names = names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies['freq_nfe']=frequencies.apply(lambda x: getNFE(x.freq), axis = 1)\n",
    "\n",
    "#give frequencies df a CHRBP_REFALT to give it a unique key to merge with later\n",
    "frequencies['CHRBP_REFALT']=frequencies.apply(lambda x: formatCHRBPREFALT(x.chr, x.start, x.ref, x.alt), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_freq=pd.merge(merge,frequencies, how = 'left', on = \"CHRBP_REFALT\")\n",
    "\n",
    "pheno_data = merge_freq[['GWAS','ID', 'CHRBP_REFALT','locnum','freq_nfe', 'DISEASE/TRAIT', 'P-VALUE', 'PMID']]\n",
    "pheno_data = pheno_data.rename(columns={\"DISEASE/TRAIT\": \"other associated disease\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pheno_data = pheno_data.drop_duplicates()\n",
    "\n",
    "pheno_data.to_csv(f\"{DATADIR}/results/PhenotypeVariantData.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
