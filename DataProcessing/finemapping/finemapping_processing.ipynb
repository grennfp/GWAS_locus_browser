{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finemapping Processing\n",
    "- **Author** - Frank Grenn\n",
    "- **Date Started** - April 2020\n",
    "- **Quick Description:** filter the finemapping data for the GWAS browser. This code filters the data by prob > 0.01, assigns variants to the browser locus numbers and looks for coding variants for each variant. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all rows from results.csv with prob > 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"/path/to/finemap/results.csv\")\n",
    "print(results.shape)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cols = results[[\"SNP\",\"chr\",\"position\", \"A1\", \"A2\", \"freq\", \"p\", \"prob\", \"log10bf\"]]\n",
    "print(results_cols.shape)\n",
    "print(results_cols.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filter = results_cols[results_cols[\"prob\"] > 0.01]\n",
    "print(results_filter.shape)\n",
    "print(results_filter.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now liftover the above df (which is in hg38 coordinates) back to hg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some identifier to the cols\n",
    "results_filter['name'] = np.arange(len(results_filter))\n",
    "print(results_filter.shape)\n",
    "print(results_filter.head())\n",
    "print(results_filter.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f_sub = results_filter[['chr','position', 'name']]\n",
    "results_f_sub['position2'] = results_f_sub['position'] + 1\n",
    "results_f_sub = results_f_sub[['chr','position', 'position2', 'name']]\n",
    "print(results_f_sub.shape)\n",
    "print(results_f_sub.head())\n",
    "results_f_sub.to_csv(\"/path/to/AppDataProcessing/finemapping/for_liftover.txt\", sep = '\\t', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the liftover results\n",
    "liftover_hg19 = pd.read_csv(\"/path/to/AppDataProcessing/finemapping/liftover_results.bed\",sep=\"\\t\",header = None)\n",
    "liftover_hg19.columns = [\"chr\", \"position_hg19\", \"position2\", \"name\"]\n",
    "liftover_hg19 = liftover_hg19[['chr','position_hg19','name']]\n",
    "print(liftover_hg19.shape)\n",
    "print(liftover_hg19.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now merge back with the original data\n",
    "results_lo = pd.merge(left = liftover_hg19, right = results_filter, on = \"name\", how = \"inner\")\n",
    "print(results_lo.shape)\n",
    "print(results_lo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also get the 90 risk variants from the results.csv  \n",
    "we will check if the new hg19 positions are in any of the loci ranges to assign locus numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci = pd.read_csv(\"/path/to/AppDataProcessing/GWAS_loci_overview.csv\")\n",
    "print(loci.shape)\n",
    "print(loci.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci['start'] = loci['BP'].str.replace(\",\",\"\").astype(int)- 1000000\n",
    "loci['end'] = loci['BP'].str.replace(\",\",\"\").astype(int)+ 1000000\n",
    "loci['CHR'] = 'chr' + loci['CHR'].astype(str)\n",
    "print(loci.shape)\n",
    "print(loci.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"/path/to/AppDataProcessing/finemapping/loci_fm_summary.csv\")\n",
    "print(summary.shape)\n",
    "print(summary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iterate over the filtered results df and assign each row to a locus number from the GWAS_loci_overview ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "have_locus = pd.DataFrame()\n",
    "results_lo['index_variant']=\"\"\n",
    "results_lo['locus number'] = \"\"\n",
    "no_locus = pd.DataFrame()\n",
    "\n",
    "for index, row in results_lo.iterrows():\n",
    "    index_row = loci[(loci[\"CHR\"] == row[\"chr_x\"]) & (loci['start']< row[\"position_hg19\"]) & (loci['end'] > row[\"position_hg19\"]) ]\n",
    "\n",
    "    #if not assigned to a locus\n",
    "    if(len(index_row) == 0):\n",
    "        print(results_lo.iloc[index,])\n",
    "        print(\"\\n\\n\\n\")\n",
    "        no_locus = no_locus.append(results_lo.loc[index])\n",
    "\n",
    "    else:\n",
    "        var = list(index_row['SNP'])[0]\n",
    "        locus = list(index_row['Locus Number'])[0]\n",
    "\n",
    "        #break\n",
    "        results_lo.at[index,'index_variant'] = var#[index, 'index_variant'] = index_row['index_variant']\n",
    "        results_lo.at[index, 'locus number'] = locus\n",
    "    \n",
    "        have_locus = have_locus.append(results_lo.loc[index])\n",
    "print(results_lo.shape)\n",
    "print(results_lo.head())\n",
    "print(\"final df:\")\n",
    "print(have_locus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(have_locus['locus number'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(have_locus.shape)\n",
    "print(results_lo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the loci that aren't covered by the results\n",
    "set(loci['Locus Number']) ^ set(have_locus['locus number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for coding variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot = pd.read_csv(\"/path/to/HRC_ouput_annovar_ALL.txt\",sep='\\t', skiprows=0, low_memory = False)\n",
    "print(annot.shape)\n",
    "print(annot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_locus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "have_locus['chr_x'] = have_locus['chr_x'].str.replace(\"chr\",\"\")\n",
    "have_locus['position_hg19'] = have_locus['position_hg19'].astype(int).astype(str)\n",
    "\n",
    "print(have_locus.shape)\n",
    "print(have_locus.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = pd.merge(left = have_locus, right = annot, left_on = [\"chr_x\",\"position_hg19\"], right_on = [\"Chr\", \"Start\"], how = \"left\")\n",
    "print(coding.shape)\n",
    "print(coding.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding.to_csv(\"/path/to/AppDataProcessing/finemapping/finemapcoding.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many coding vairants we have\n",
    "aa_changes = [ c for c in coding['AAChange.refGene'] if  '.' is not c ]\n",
    "len(aa_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make DataFrames containing rows with and without coding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_coding = coding[coding['ExonicFunc.refGene']!='.']\n",
    "print(fm_coding.shape)\n",
    "fm_not_coding = coding[coding['ExonicFunc.refGene']=='.']\n",
    "print(fm_not_coding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge the finemapping results with coding variants with coding variant data from the app to look for which AA change to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_coding_var = pd.read_csv(\"/path/to/AppDataProcessing/results/CodingVariants.csv\")\n",
    "print(app_coding_var.shape)\n",
    "print(app_coding_var.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(left = fm_coding, right = app_coding_var,left_on = \"SNP\", right_on = \"ID\" , how = \"left\")\n",
    "merged.shape\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_app_coding = merged[merged['ID'].notna()].reset_index()\n",
    "has_app_coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if all indices printed then can use the AA change from the other app data (to fix multiple AA changes)\n",
    "for index, row in has_app_coding.iterrows():\n",
    "    if(row['AA Change'] in row['AAChange.refGene']):\n",
    "        print(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_app_coding.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_app_coding = has_app_coding[['locus number_x','SNP','Chr','position_hg19','Ref','Alt','freq','p','prob','log10bf','Func.refGene','ExonicFunc.refGene','AA Change']]\n",
    "has_app_coding.columns = fm_not_coding.columns = ['locus number_x','SNP','Chr','position_hg19','Ref','Alt','freq','p','prob','log10bf','Func.refGene','ExonicFunc.refGene','AAChange.refGene']\n",
    "has_app_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now the ones we still need to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_app_coding = merged[merged['ID'].isna()]\n",
    "no_app_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if just one AAChange.refGene then we should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_app_coding_single = no_app_coding[no_app_coding['AAChange.refGene'].str.count(',')==0]\n",
    "no_app_coding_single = no_app_coding_single[['locus number_x','SNP','Chr','position_hg19','Ref','Alt','freq','p','prob','log10bf','Func.refGene','ExonicFunc.refGene','AAChange.refGene']]\n",
    "no_app_coding_single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if multiple then we need to find the one we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_app_coding_multi = no_app_coding[no_app_coding['AAChange.refGene'].str.count(',')!=0]\n",
    "no_app_coding_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use gnomad to get the best transcript for each SNP  \n",
    "rs72819488:ENST00000317620  \n",
    "rs4858798:ENST00000328631  \n",
    "rs2230457:ENST00000304400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then can use this R code to filter for the NCBI/refSeq ids we need to pick the right one\n",
    "\n",
    "```\n",
    "library(biomaRt)\n",
    "ensembl <- useMart(\"ensembl\", dataset=\"hsapiens_gene_ensembl\")\n",
    "values <- c(\"ENST00000317620.9\",\"ENST00000328631.5\",\"ENST00000304400.7\")\n",
    "values <- c(\"ENST00000317620\",\"ENST00000328631\",\"ENST00000304400\")\n",
    "results <- getBM(attributes = c(\"refseq_mrna\", \"ensembl_transcript_id\", \"hgnc_symbol\", filters = \"ensembl_transcript_id\"), values = values, mart = ensembl)\n",
    "\n",
    "for(value in values)\n",
    "{\n",
    "  print(value)\n",
    "  print(results[which(results$ensembl_transcript_id == value),]$refseq_mrna)\n",
    "  print(\"\\n\")\n",
    "}\n",
    "#listDatasets(useMart(\"ensembl\"))\n",
    "#listFilters(ensembl)\n",
    "#listAttributes(ensembl)\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rs72819488:ENST00000317620:NM_001165978  \n",
    "rs4858798:ENST00000328631:NM_001005909 or NM_016291  \n",
    "rs2230457:ENST00000304400:NM_001364583 or NM_000919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq_ids = [\"NM_001165978\",\"NM_001005909\",\"NM_016291\",\"NM_001364583\",\"NM_000919\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if all indices printed then can use the AA change from the other app data (to fix multiple AA changes)\n",
    "for index, row in no_app_coding_multi.iterrows():\n",
    "    split = row['AAChange.refGene'].split(\",\")\n",
    "    for val in split:\n",
    "        for rs in refseq_ids:\n",
    "            if(rs in val):\n",
    "                print(val)\n",
    "                print(rs)\n",
    "#repeat to assign\n",
    "for index, row in no_app_coding_multi.iterrows():\n",
    "    split = row['AAChange.refGene'].split(\",\")\n",
    "    for val in split:\n",
    "        for rs in refseq_ids:\n",
    "            if(rs in val):\n",
    "                no_app_coding_multi.at[index,'AAChange.refGene'] = val\n",
    "\n",
    "no_app_coding_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_app_coding_multi = no_app_coding_multi[['locus number_x','SNP','Chr','position_hg19','Ref','Alt','freq','p','prob','log10bf','Func.refGene','ExonicFunc.refGene','AAChange.refGene']]\n",
    "no_app_coding_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format the df with no coding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_not_coding.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_not_coding = fm_not_coding[['locus number','SNP','Chr','position_hg19','Ref','Alt','freq','p','prob','log10bf','Func.refGene','ExonicFunc.refGene','AAChange.refGene']]\n",
    "fm_not_coding.columns = ['locus number_x','SNP','Chr','position_hg19','Ref','Alt','freq','p','prob','log10bf','Func.refGene','ExonicFunc.refGene','AAChange.refGene']\n",
    "fm_not_coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now append everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fm_not_coding.shape)\n",
    "print(no_app_coding_multi.shape)\n",
    "print(no_app_coding_single.shape)\n",
    "print(has_app_coding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fm_not_coding.columns)\n",
    "print(no_app_coding_multi.columns)\n",
    "print(no_app_coding_single.columns)\n",
    "print(has_app_coding.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = no_app_coding_multi.append(no_app_coding_single).append(fm_not_coding).append(has_app_coding)\n",
    "final_df.columns = ['Locus Number','SNP','Chr','Position', 'Ref', 'Alt', 'Freq', 'P-value', 'prob', 'log10bf','Func.refGene','ExonicFunc.refGene','AAChange.refGene']\n",
    "final_df = final_df.replace(\".\",\"NA\")\n",
    "final_df = final_df.drop_duplicates()\n",
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/path/to/AppDataProcessing/results/fineMappingFilteredData.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"/path/to/AppDataProcessing/results/fineMappingFilteredData.csv\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Chr'] = 'chr'+final_df['Chr'].astype(str)\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = final_df[['Chr','Position','SNP']]\n",
    "variants  = variants.sort_values(by=['Chr','Position'])\n",
    "\n",
    "\n",
    "variants = variants[['Chr','Position','Position','SNP']]\n",
    "print(variants.shape)\n",
    "print(variants.head())\n",
    "variants.to_csv(\"/path/to/AppDataProcessing/finemapping/filtered.bed\",index=None,header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refhg19 = pd.read_csv(\"/path/to/refFlat_HG19.txt\",sep='\\t',header =None)\n",
    "\n",
    "print(refhg19.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ref = refhg19.iloc[:,[2,4,5,0]]\n",
    "ref.columns = ['chr','start','end','gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref  = ref.sort_values(by=['chr','start','end'])\n",
    "print(ref.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref.to_csv(\"/path/to/ref.bed\",index=None,header=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bedtools intersect -a AppDataProcessing/finemapping/filtered.bed -b ref.bed -wb > test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bedtools closest -a AppDataProcessing/finemapping/filtered.bed -b ref.bed -wb > test_closest.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"/path/to/test_closest.txt\",sep='\\t',header=None)\n",
    "print(results.shape)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_neargene = results.iloc[:,[3,7]]\n",
    "rs_neargene.columns = ['RSID','NearGene']\n",
    "print(rs_neargene.shape)\n",
    "print(rs_neargene.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rs_neargene.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(left = final_df, right = rs_neargene, left_on = 'SNP', right_on= 'RSID', how = 'inner')\n",
    "print(merge.shape)\n",
    "print(merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_nodup = merge.drop_duplicates()\n",
    "print(merge_nodup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge_nodup.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_nodup.to_csv(\"/path/to/results.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.shape)\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup = final_df.drop_duplicates()\n",
    "print(nodup.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
