{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Coding Variant Files\n",
    "- **Author** - Frank Grenn\n",
    "- **Date Started** - April 2020\n",
    "- **Quick Description:** annotate the risk variants from all gwas for the app with data from annovar and get tagging snps. Then get the coding variants from these and get their LD values, CADD scores and frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/path/to/AppDataProcessing'\n",
    "WRKDIR = f\"{DATADIR}/codingvars\"\n",
    "TMPDIR = f\"{WRKDIR}/temp\"\n",
    "\n",
    "HARDCALLS_DIR = \"/path/to/PD_FINAL_PLINK_2018\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {TMPDIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Tag GWAS Variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwas = pd.read_csv(f\"{DATADIR}/gwas_risk_variants.csv\")\n",
    "print(gwas.shape)\n",
    "print(gwas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate chr:bp files\n",
    "update chr and bp index for gwas csv used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrbp_index = 3\n",
    "chr_index = 2\n",
    "loc_index = 5\n",
    "gwas_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WRKDIR}/get_05_tags.swarm\",\"w\") as swarm_file:\n",
    "    for i in range(0,len(gwas.index)):\n",
    "        chrbp = gwas.iloc[i,chrbp_index]\n",
    "        gwas_str = gwas.iloc[i,gwas_index]\n",
    "        !echo {chrbp} > {TMPDIR}/{chrbp}_{gwas_str}_gwas.txt\n",
    "        \n",
    "        swarm_file.write(f\"plink --bfile {HARDCALLS_DIR}/HARDCALLS_PD_september_2018_no_cousins --tag-r2 0.5 --memory 135000 --threads 19 --show-tags {TMPDIR}/{chrbp}_{gwas_str}_gwas.txt --chr {gwas.iloc[i,chr_index]} --out {TMPDIR}/{chrbp}_{gwas_str}_gwas\\n\")\n",
    "swarm_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"swarm -f {WRKDIR}/get_05_tags.swarm -g 10 -t 20 --module=plink\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now Annotate the Tags\n",
    "add locus numbers and the gwas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(gwas.index)):\n",
    "    chrbp = gwas.iloc[i,chrbp_index]\n",
    "\n",
    "    locus = gwas.iloc[i, loc_index]\n",
    "    \n",
    "    gwas_str = gwas.iloc[i, gwas_index]\n",
    "    !sed -i.bkp 's/^/{gwas_str}\\t{locus}\\t/' {TMPDIR}/{chrbp}_{gwas_str}_gwas.tags\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {TMPDIR}/*.tags > {WRKDIR}/ALL_TAGS.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now add annovar data and rsids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv(f\"{WRKDIR}/ALL_TAGS.txt\", header=None,sep='\\t')\n",
    "tags.columns = [\"GWAS\",\"locnum\",\"chrbp\"]\n",
    "print(tags.shape)\n",
    "print(tags.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annovar = pd.read_csv(\"/path/to/HRC_ouput_annovar_ALL.txt\",sep='\\t')\n",
    "print(annovar.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RS = pd.read_csv(\"/path/to/HRC_RS_conversion_final.txt\",sep='\\t')\n",
    "print(RS.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM = pd.merge(left = tags, right = RS, left_on = \"chrbp\",right_on = \"POS\", how = \"left\")\n",
    "MM2 = pd.merge(left = MM, right = annovar, left_on = \"ID\",right_on = \"avsnp142\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MM2.shape)\n",
    "print(MM2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add the associated disease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(f\"{DATADIR}/phenovars/GWAS_catalogv1.0.2-associations.txt\",sep='\\t',encoding='latin1')\n",
    "print(catalog.shape)\n",
    "print(catalog.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM2_disease = pd.merge(left = MM2, right = catalog, left_on = 'ID',right_on = 'SNPS', how = 'left')\n",
    "MM2_disease = MM2_disease[['GWAS', 'ID', 'Chr', 'Start', 'End', 'locnum', 'Ref', 'Alt', 'DISEASE/TRAIT','Func.refGene', 'Gene.refGene', 'GeneDetail.refGene', 'ExonicFunc.refGene', 'AAChange.refGene']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM2_disease.to_csv(f\"{WRKDIR}/annotated_R05_tags_all_gwas.txt\", sep = '\\t',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get Coding Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding  = MM2_disease[MM2_disease['Func.refGene'].str.contains('exonic',na=False)]\n",
    "coding = coding[coding['ExonicFunc.refGene'].str.contains('nonsynonymous')]\n",
    "print(coding.shape)\n",
    "print(coding.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding = coding[['GWAS','ID','Chr','Start','End','locnum','Ref','Alt','DISEASE/TRAIT','Func.refGene','Gene.refGene','GeneDetail.refGene','ExonicFunc.refGene','AAChange.refGene']]\n",
    "coding = coding.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding.to_csv(f\"{WRKDIR}/CodingVariant.csv\",index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Get CADD Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WRKDIR}/get_CADD_annovar.sh\",\"w\") as bash_file:\n",
    "    bash_file.write(f'''#!/bin/bash\\n\\\n",
    "module load annovar\\n\\\n",
    "awk -F',' '{{print $3,$4,$5,$7,$8}}' '{WRKDIR}/CodingVariant.csv' > {WRKDIR}/codingvars.avinput\\n\\\n",
    "annotate_variation.pl --filter --build hg19 --dbtype cadd --buildver hg19 --otherinfo {WRKDIR}/codingvars.avinput $ANNOVAR_DATA/hg19''')\n",
    "bash_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sbatch {WRKDIR}/get_CADD_annovar.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Get Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WRKDIR}/get_frequencies_annovar.sh\",\"w\") as bash_file:\n",
    "    bash_file.write(f'''#!/bin/bash\\n\\\n",
    "module load annovar\\n\\\n",
    "awk -F',' '{{print $3,$4,$5,$7,$8}}' '{WRKDIR}/CodingVariant.csv' > codingvars.avinput\\n\\\n",
    "annotate_variation.pl --filter --build hg19 --dbtype gnomad211_genome --buildver hg19 --otherinfo {WRKDIR}/codingvars.avinput $ANNOVAR_DATA/hg19''')\n",
    "bash_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sbatch {WRKDIR}/get_frequencies_annovar.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Get LD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv(f\"{DATADIR}/gwas_risk_variants.csv\")\n",
    "print(variants.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make a ranges file to speed up plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = variants[['CHR','BP','BP']]\n",
    "ranges['ID']=\"r\"+ranges.index.astype(str)\n",
    "ranges.columns = ['CHR','Start','End','ID']\n",
    "ranges['Start'] = ranges['Start'].apply(lambda x: max(0,x - 1000000))\n",
    "ranges['End'] = ranges['End'] + 1000000\n",
    "print(ranges.shape)\n",
    "print(ranges.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges.to_csv(f\"{WRKDIR}/LD/ranges.txt\",sep='\\t',index=None,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run LD Commands\n",
    "probably better way to do this but works for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!mkdir {WRKDIR}/LD/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{WRKDIR}/LD/calculateLD.swarm\", 'w') as outfile:\n",
    "    for i in range(len(variants.index)):\n",
    "        locus = variants.iloc[i]['Locus Number']\n",
    "        #print(locus)\n",
    "    \n",
    "        locus_codingvars = coding.loc[coding['locnum'] == locus]\n",
    "    \n",
    "        snp1 = str(variants.iloc[i]['CHR']) + \":\" + str(variants.iloc[i]['BP'])\n",
    "\n",
    "        if(len(locus_codingvars.index)!=0):\n",
    "            for i in range(len(locus_codingvars.index)):\n",
    "\n",
    "                snp2 = str(locus_codingvars.iloc[i]['Chr']) + \":\" + str(locus_codingvars.iloc[i]['Start'])\n",
    "\n",
    "\n",
    "                outfile.write(f\"plink --bfile /path/to/HARDCALLS_PD_september_2018_no_cousins --ld {snp1} {snp2} --extract range {WRKDIR}/LD/ranges.txt --out {snp1}_{snp2}\\n\")    \n",
    "outfile.close()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the swarm file\n",
    "print(f\"cd {WRKDIR}/LD/out\")\n",
    "print(f\"swarm -f {WRKDIR}/LD/calculateLD.swarm --partition quick --module plink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read stuff\n",
    "df = pd.DataFrame(columns=['rsid1','snp1','rsid2','snp2','r2','dprime'])\n",
    "for i in range(len(variants.index)):\n",
    "    locus = variants.iloc[i]['Locus Number']\n",
    "    #print(locus)\n",
    "    \n",
    "    locus_codingvars = coding.loc[coding['locnum'] == locus]\n",
    "    #print(locus_phenovars)\n",
    "    \n",
    "    snp1 = str(variants.iloc[i]['CHR']) + \":\" + str(variants.iloc[i]['BP'])\n",
    "    rsid1 = variants.iloc[i]['RSID']\n",
    "    if(len(locus_codingvars.index)!=0):\n",
    "        for i in range(len(locus_codingvars.index)):\n",
    "            #reset the read string to null\n",
    "            dataline='null'\n",
    "            snp2 = str(locus_codingvars.iloc[i]['Chr']) + \":\" + str(locus_codingvars.iloc[i]['Start'])\n",
    "            rsid2 = locus_codingvars.iloc[i]['ID']\n",
    "            #print(\"{} {}\".format(snp1, snp2))\n",
    "\n",
    "\n",
    "            \n",
    "            file = open(f\"{WRKDIR}/LD/out/\"+str(snp1)+\"_\"+str(snp2)+\".log\",\"r\")\n",
    "            \n",
    "            for line in file:\n",
    "                if re.search(\"R-sq\", line):\n",
    "                    dataline = line\n",
    "                    break\n",
    "            \n",
    "            #only add new data if 'R-sq' was found (meaning there was data in the log file and the 'null' value assigned earlier was overwritten)\n",
    "            if(dataline!='null'):\n",
    "                #mess with the strings\n",
    "                dataline = dataline.strip('R-sq = ')\n",
    "                dataline = dataline.strip(' ')\n",
    "                splitdata = dataline.split(\"D' =\")\n",
    "                Rsq = splitdata[0]\n",
    "                dprime = splitdata[1]\n",
    "            \n",
    "                df = df.append({'rsid1': rsid1,'snp1': snp1,'rsid2':rsid2, 'snp2': snp2, 'r2':Rsq.strip(' '), 'dprime':dprime.strip('\\n')}, ignore_index = True)\n",
    "        \n",
    "print(len(df.index))\n",
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{DATADIR}/results/CodingVariantLD.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Combine Everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some formatting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def formatCHRBPREFALT(chr,bp,ref,alt):\n",
    "\treturn str(chr)+\":\"+str(bp)+\":\"+str(ref)+\":\"+str(alt)\n",
    "\t\n",
    "def getNFE(frequencies):\n",
    "\tfreq = re.split(\",\", frequencies)[9]\n",
    "\treturn freq\n",
    "\t\n",
    "def getFirstAAChange(AAchanges):\n",
    "\treturn re.split(\",\", AAchanges)[0]\n",
    "\n",
    "def getFirstGene(genes):\n",
    "\treturn re.split(\";\", genes)[0]\n",
    "\n",
    "#separate raw and phred cadd scores, and return phred score\n",
    "def getCADDPhred(cadd):\n",
    "    caddphred = re.split(\",\", cadd)[1]\n",
    "    return caddphred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge with frequency data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variants = pd.read_csv(f\"{WRKDIR}/CodingVariant.csv\")\n",
    "\n",
    "variants['CHRBP_REFALT']=variants.apply(lambda x: formatCHRBPREFALT(x.Chr, x.Start, x.Ref, x.Alt), axis = 1)\n",
    "\n",
    "#array for frequency df column names since annovar doesn't generate column names\n",
    "names = [\"db\", \"freq\", \"chr\", \"start\", \"end\", \"ref\", \"alt\"]\n",
    "frequencies = pd.read_csv(f\"{WRKDIR}/codingvars.avinput.hg19_gnomad211_genome_dropped\", sep=\"\\s\", names = names)\n",
    "\n",
    "frequencies['freq_nfe']=frequencies.apply(lambda x: getNFE(x.freq), axis = 1)\n",
    "\n",
    "#give frequencies df a CHRBP_REFALT to give it a unique key to merge with later\n",
    "frequencies['CHRBP_REFALT']=frequencies.apply(lambda x: formatCHRBPREFALT(x.chr, x.start, x.ref, x.alt), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge=pd.merge(variants,frequencies, how = 'left', on = \"CHRBP_REFALT\")\n",
    "merge = merge[['GWAS', 'ID', 'CHRBP_REFALT','locnum','Gene.refGene','freq_nfe','AAChange.refGene']]\n",
    "print(merge.shape)\n",
    "print(merge.head())\n",
    "print(merge.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge with CADD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"db\", \"cadd\", \"chr\", \"start\", \"end\", \"ref\", \"alt\"]\n",
    "cadd = pd.read_csv(f\"{WRKDIR}/codingvars.avinput.hg19_cadd_dropped\", sep=\"\\s\", names = names)\n",
    "\n",
    "cadd['cadd_phred'] = cadd.apply(lambda x: getCADDPhred(x.cadd), axis = 1)\n",
    "\n",
    "#give cadd df a CHRBP_REFALT to give it a unique key to merge with later\n",
    "cadd['CHRBP_REFALT']=cadd.apply(lambda x: formatCHRBPREFALT(x.chr, x.start, x.ref, x.alt), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_final = pd.merge(merge, cadd, how = 'left', on = \"CHRBP_REFALT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### just get the first AA change\n",
    "may need to manually edit some of these as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_final['AA Change']=merge_final.apply(lambda x: getFirstAAChange(x['AAChange.refGene']), axis = 1)\n",
    "\n",
    "merge_final['Gene.refGene'] = merge_final.apply(lambda x: getFirstGene(x['Gene.refGene']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_data = merge_final[['GWAS','ID', 'CHRBP_REFALT','locnum','Gene.refGene','AA Change','freq_nfe','cadd_phred']]\n",
    "\n",
    "coding_data = coding_data.drop_duplicates()\n",
    "\n",
    "coding_data.to_csv(f\"{DATADIR}/results/CodingVariants.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
